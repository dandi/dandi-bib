#!/usr/bin/env python
"""
Update a Zotero collection with bibliography entries from a BibTeX file.

This script will:
- Parse a BibTeX file (e.g., dandi.bib)
- Connect to Zotero using the API
- Find existing items in the specified collection by DOI
- Update existing items if metadata has changed
- Add new items that don't exist yet
- Avoid creating duplicates

Usage:
    ./update-zotero-collection --api-key YOUR_API_KEY --group-id 5774211 \
        --collection-key T8I34DL3 --bibfile dandi.bib

Requirements:
    - pyzotero: pip install pyzotero
    - bibtexparser: pip install bibtexparser
"""

import argparse
import logging
import re
import sys
from typing import Dict, List

import bibtexparser
from pyzotero import zotero

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stderr,
)

lgr = logging.getLogger(__name__)

# Zotero API pagination limit (100 is the maximum allowed by the API)
ZOTERO_API_LIMIT = 100


def parse_bibtex_file(bibfile: str) -> List[Dict]:
    """Parse a BibTeX file and return list of entries."""
    lgr.info(f"Parsing BibTeX file: {bibfile}")
    with open(bibfile, "r", encoding="utf-8") as f:
        bib_database = bibtexparser.load(f)
    lgr.info(f"Found {len(bib_database.entries)} entries in BibTeX file")
    return bib_database.entries


def bibtex_to_zotero_item(entry: Dict) -> Dict:
    """Convert a BibTeX entry to Zotero item format."""
    # Map BibTeX entry types to Zotero item types
    type_mapping = {
        "article": "journalArticle",
        "book": "book",
        "inproceedings": "conferencePaper",
        "misc": "dataset",  # DANDI uses @misc for datasets, map to dataset type
        "phdthesis": "thesis",
        "techreport": "report",
    }

    entry_type = entry.get("ENTRYTYPE", "misc").lower()
    zotero_type = type_mapping.get(entry_type, "dataset")

    # Build the Zotero item
    item = {
        "itemType": zotero_type,
        "title": entry.get("title", ""),
        "url": entry.get("url", ""),
        "date": entry.get("year", ""),
        "extra": "",  # We'll add additional fields here
    }

    # Extract DOI
    doi = entry.get("doi", "")
    if doi:
        # dataset type supports DOI as a direct field
        if zotero_type in [
            "journalArticle",
            "conferencePaper",
            "book",
            "thesis",
            "report",
            "dataset",
        ]:
            item["DOI"] = doi
        else:
            # For types that don't support DOI, add to extra field
            item["extra"] += f"DOI: {doi}\n"

    # Extract authors
    if "author" in entry:
        authors_str = entry["author"]
        # Split by "and" and parse names
        author_list = [a.strip() for a in authors_str.split(" and ")]
        item["creators"] = []
        for author in author_list:
            # Handle "Last, First" or "First Last" formats
            if "," in author:
                parts = author.split(",", 1)
                last_name = parts[0].strip()
                first_name = parts[1].strip() if len(parts) > 1 else ""
            else:
                # Assume last word is last name
                parts = author.rsplit(None, 1)
                first_name = parts[0] if len(parts) > 1 else ""
                last_name = parts[-1]

            item["creators"].append(
                {
                    "creatorType": "author",
                    "firstName": first_name,
                    "lastName": last_name,
                }
            )

    # Add publisher / repository
    # For datasets, publisher goes to "repository" field; for others use publisher field
    if "publisher" in entry:
        publisher = entry["publisher"]
        if zotero_type == "dataset":
            # dataset type has "repository" field instead of publisher
            item["repository"] = publisher
        elif zotero_type in [
            "journalArticle",
            "book",
            "conferencePaper",
            "thesis",
            "report",
        ]:
            item["publisher"] = publisher
        else:
            # Add to extra field for types that don't support publisher
            item["extra"] += f"Publisher: {publisher}\n"

    # Extract version from DOI for datasets
    # DOI format: 10.48324/DANDI.000027/0.210831.2033
    if zotero_type == "dataset" and doi:
        doi_parts = doi.split("/")
        if len(doi_parts) >= 2:
            version = doi_parts[-1]
            # Check if it looks like a version (not just a dandiset ID)
            if "." in version and len(version) > 6:
                item["versionNumber"] = version

    # Add keywords as tags
    if "keywords" in entry:
        keywords = entry["keywords"]
        # Split by comma and filter out empty strings
        tags = [{"tag": k.strip()} for k in keywords.split(",") if k.strip()]
        if tags:  # Only add tags if there are any non-empty ones
            item["tags"] = tags

    # Add abstract if available
    if "abstract" in entry:
        item["abstractNote"] = entry["abstract"]

    # Store the BibTeX key as citation key in extra field
    # Zotero uses "Citation Key: value" format in extra field for Better BibTeX compatibility
    # Replace '/' with '@' since '/' may not be valid in citation keys
    if "ID" in entry:
        bibtex_id = entry["ID"]
        citation_key = bibtex_id.replace("/", "@")
        item["extra"] += f"Citation Key: {citation_key}\n"

        # Add version info to extra field for BibTeX export compatibility
        # (since BibTeX doesn't have a standard version field)
        if doi:
            doi_parts = doi.split("/")
            if len(doi_parts) >= 2:
                version = doi_parts[-1]
                # Check if it looks like a version (not just a dandiset ID)
                if "." in version and len(version) > 6:
                    # For "latest" entries (no version in ID), use "Current version:"
                    if "/" not in bibtex_id and "@" not in bibtex_id:
                        item["extra"] += f"Current version: {version}\n"
                    else:
                        # For versioned entries, use "Version:"
                        item["extra"] += f"Version: {version}\n"

    return item


def get_existing_items(zot: zotero.Zotero, collection_key: str) -> Dict[str, Dict]:
    """
    Retrieve all existing items in the collection.
    Returns a dict mapping citation key to item data.
    """
    lgr.info(f"Fetching existing items from collection {collection_key}")

    # Fetch all items with pagination
    all_items = []
    start = 0

    while True:
        lgr.debug(f"Fetching items starting at {start}, limit {ZOTERO_API_LIMIT}")
        items = zot.collection_items(
            collection_key, limit=ZOTERO_API_LIMIT, start=start
        )
        if not items:
            break
        all_items.extend(items)
        lgr.debug(f"Fetched {len(items)} items, total so far: {len(all_items)}")
        if len(items) < ZOTERO_API_LIMIT:
            # Last page
            break
        start += ZOTERO_API_LIMIT

    lgr.info(f"Fetched total of {len(all_items)} items from collection")

    citation_key_map = {}
    for item in all_items:
        # Skip notes, attachments, etc.
        if item["data"].get("itemType") in ["note", "attachment"]:
            continue

        # Extract citation key from extra field
        citation_key = None
        if "extra" in item["data"]:
            for line in item["data"]["extra"].split("\n"):
                if line.startswith("Citation Key:"):
                    citation_key = line.split(":", 1)[1].strip()
                    break

        if citation_key:
            citation_key_map[citation_key] = item
        else:
            lgr.debug(
                f"Item {item.get('key', 'unknown')} has no citation key, skipping"
            )

    lgr.info(
        f"Found {len(citation_key_map)} existing items with citation keys in collection"
    )
    return citation_key_map


def items_are_different(existing: Dict, new: Dict) -> bool:
    """
    Compare two items to see if they're different.
    Returns True if update is needed.

    For items with Citation Key in extra field, we only compare the citation key
    itself, not other metadata (like "Current version") which may change.
    """
    # Extract citation keys from extra field if present
    existing_citation_key = None
    new_citation_key = None

    if "extra" in existing:
        for line in existing["extra"].split("\n"):
            if line.startswith("Citation Key:"):
                existing_citation_key = line.split(":", 1)[1].strip()
                break

    if "extra" in new:
        for line in new["extra"].split("\n"):
            if line.startswith("Citation Key:"):
                new_citation_key = line.split(":", 1)[1].strip()
                break

    # If both have citation keys, compare only the citation key
    # (not the full extra field, since other metadata may change)
    if existing_citation_key and new_citation_key:
        if existing_citation_key != new_citation_key:
            return True
        # For citation-key items, skip extra field comparison below
        # Include dataset-specific fields (repository, versionNumber, DOI)
        fields_to_compare = [
            "title",
            "date",
            "url",
            "abstractNote",
            "publisher",
            "repository",
            "versionNumber",
            "DOI",
        ]
    else:
        # No citation keys, compare everything including extra
        fields_to_compare = [
            "title",
            "date",
            "url",
            "abstractNote",
            "publisher",
            "repository",
            "versionNumber",
            "DOI",
            "extra",
        ]

    for field in fields_to_compare:
        existing_val = existing.get(field, "").strip()
        new_val = new.get(field, "").strip()
        if existing_val != new_val:
            lgr.debug(f"Field '{field}' differs:")
            lgr.debug(f"  Existing: {existing_val[:100]}")
            lgr.debug(f"  New: {new_val[:100]}")
            return True

    # Compare creators
    existing_creators = existing.get("creators", [])
    new_creators = new.get("creators", [])

    if len(existing_creators) != len(new_creators):
        lgr.debug(
            f"Creators count differs: {len(existing_creators)} vs {len(new_creators)}"
        )
        return True

    for i, (ex_creator, new_creator) in enumerate(zip(existing_creators, new_creators)):
        if ex_creator.get("lastName") != new_creator.get("lastName") or ex_creator.get(
            "firstName"
        ) != new_creator.get("firstName"):
            lgr.debug(f"Creator {i} differs:")
            lgr.debug(
                f"  Existing: {ex_creator.get('firstName')} {ex_creator.get('lastName')}"
            )
            lgr.debug(
                f"  New: {new_creator.get('firstName')} {new_creator.get('lastName')}"
            )
            return True

    # Compare tags
    existing_tags = {t.get("tag", "") for t in existing.get("tags", [])}
    new_tags = {t.get("tag", "") for t in new.get("tags", [])}

    if existing_tags != new_tags:
        lgr.debug("Tags differ:")
        lgr.debug(f"  Existing: {existing_tags}")
        lgr.debug(f"  New: {new_tags}")
        return True

    return False


def clear_collection(
    zot: zotero.Zotero, collection_key: str, dry_run: bool = False
) -> None:
    """
    Delete all items from a Zotero collection.

    Args:
        zot: Zotero API connection
        collection_key: The collection to clear
        dry_run: If True, only report what would be deleted
    """
    lgr.info(f"Clearing all items from collection {collection_key}")

    # Get all items in the collection
    all_items = []
    start = 0

    while True:
        lgr.debug(f"Fetching items starting at {start}, limit {ZOTERO_API_LIMIT}")
        items = zot.collection_items(
            collection_key, limit=ZOTERO_API_LIMIT, start=start
        )
        if not items:
            break
        all_items.extend(items)
        lgr.debug(f"Fetched {len(items)} items, total so far: {len(all_items)}")
        if len(items) < ZOTERO_API_LIMIT:
            break
        start += ZOTERO_API_LIMIT

    lgr.info(f"Found {len(all_items)} items to delete")

    if not all_items:
        lgr.info("Collection is already empty")
        return

    if dry_run:
        lgr.info("DRY RUN - would delete the following items:")

    # Delete items (or show what would be deleted in dry-run)
    deleted_count = 0
    for item in all_items:
        item_key = item.get("key")
        if not item_key:
            continue

        title = item["data"].get("title", "No title")
        item_type = item["data"].get("itemType", "unknown")
        # Truncate long titles
        if len(title) > 60:
            title = title[:57] + "..."

        try:
            if dry_run:
                lgr.info(f"  [{item_type:15s}] {item_key}: {title}")
            else:
                lgr.debug(f"Deleting item {item_key}: {title}")
                zot.delete_item(item)
            deleted_count += 1
        except Exception as e:
            lgr.error(f"Error deleting item {item_key}: {e}")

    if dry_run:
        lgr.info("=" * 60)
        lgr.info(f"DRY RUN Summary: Would delete {deleted_count} items")
    else:
        lgr.info(f"Successfully deleted {deleted_count} items from collection")


def update_zotero_collection(
    zot: zotero.Zotero,
    collection_key: str,
    bib_entries: List[Dict],
    dry_run: bool = False,
    min_match_threshold: float = 0.95,
    on_error: str = "exit",
    act_only_on: str = None,
    clear_first: bool = False,
) -> None:
    """
    Update the Zotero collection with entries from BibTeX file.

    Args:
        on_error: What to do on error - 'exit' to stop immediately, 'continue' to keep going
        act_only_on: Optional regex pattern to filter DOIs to act on
        clear_first: If True, delete all items from collection before syncing
    """
    # Clear collection if requested
    if clear_first:
        clear_collection(zot, collection_key, dry_run)
        if dry_run:
            lgr.info("DRY RUN - would clear collection before syncing")

    # Get existing items
    existing_items = get_existing_items(zot, collection_key)

    # Build local citation key set - includes ALL entries for validation
    # Convert BibTeX IDs to citation key format (/ -> @)
    local_citation_keys = set()
    for entry in bib_entries:
        bibtex_id = entry.get("ID", "")
        if bibtex_id:
            citation_key = bibtex_id.replace("/", "@")
            local_citation_keys.add(citation_key)

    lgr.info(f"Local BibTeX file has {len(local_citation_keys)} unique citation keys")

    # Validation: Check how many existing Zotero items are found locally
    # NOTE: This validation checks ALL items, regardless of --act-only-on filter
    # The filter only applies to actual update/add operations below
    if existing_items and not act_only_on:
        matched_count = 0
        unmatched_keys = []

        for existing_key, item in existing_items.items():
            if existing_key in local_citation_keys:
                matched_count += 1
            else:
                unmatched_keys.append(existing_key)

        match_rate = matched_count / len(existing_items)
        lgr.info(
            f"Match validation: {matched_count}/{len(existing_items)} "
            f"({match_rate:.1%}) of existing Zotero items found in local BibTeX"
        )

        if match_rate < min_match_threshold:
            lgr.error(
                f"VALIDATION FAILED: Only {match_rate:.1%} of existing Zotero items "
                f"were found in the local BibTeX file (threshold: {min_match_threshold:.1%})"
            )
            lgr.error(f"Missing {len(unmatched_keys)} items from local BibTeX:")
            for key in unmatched_keys[:10]:  # Show first 10
                lgr.error(f"  - {key}")
            if len(unmatched_keys) > 10:
                lgr.error(f"  ... and {len(unmatched_keys) - 10} more")
            lgr.error(
                "This suggests either:\n"
                "  1. Local BibTeX file is incomplete/outdated\n"
                "  2. Zotero collection has items not in DANDI archive\n"
                "  3. Citation key mismatch between local and remote\n"
                "Aborting to prevent data loss. Use --force to override (not yet implemented)."
            )
            sys.exit(1)

        lgr.info("Validation passed! Proceeding with sync...")
    elif existing_items and act_only_on:
        lgr.info(
            f"Skipping validation check due to --act-only-on filter: {act_only_on}"
        )
        lgr.info("Will only act on items matching the filter pattern")
    else:
        lgr.info("No existing items in Zotero collection, will add all new items")

    # Track what we do
    added_count = 0
    updated_count = 0
    skipped_count = 0
    error_count = 0

    # Compile regex pattern if provided
    doi_filter_pattern = None
    if act_only_on:
        doi_filter_pattern = re.compile(act_only_on, re.IGNORECASE)
        lgr.info(f"Filtering DOIs with pattern: {act_only_on}")

    # Process each BibTeX entry
    for entry in bib_entries:
        # Get the BibTeX ID and convert to citation key format (/ -> @)
        bibtex_id = entry.get("ID", "")
        if not bibtex_id:
            lgr.debug("Skipping entry with no ID")
            continue

        citation_key = bibtex_id.replace("/", "@")

        # Get DOI for filtering purposes
        doi = entry.get("doi", "")

        # Filter by pattern if specified (applies to DOI)
        if doi_filter_pattern and doi and not doi_filter_pattern.search(doi):
            lgr.debug(f"Skipping entry {citation_key} - doesn't match filter")
            continue

        try:
            # Convert to Zotero format
            new_item = bibtex_to_zotero_item(entry)

            if citation_key in existing_items:
                # Item exists - check if update is needed
                existing = existing_items[citation_key]
                if items_are_different(existing["data"], new_item):
                    lgr.info(f"Updating item: {citation_key} - {doi}")
                    # Log what changed for debugging
                    lgr.debug(
                        f"  Existing extra: {existing['data'].get('extra', '')[:100]}"
                    )
                    lgr.debug(f"  New extra: {new_item.get('extra', '')[:100]}")
                    if not dry_run:
                        # Update the item
                        new_item["version"] = existing["version"]
                        new_item["key"] = existing["key"]
                        zot.update_item(new_item)
                    updated_count += 1
                else:
                    lgr.debug(f"Skipping unchanged item: {citation_key}")
                    skipped_count += 1
            else:
                # New item - add it
                lgr.info(f"Adding new item: {citation_key} - {doi}")
                if not dry_run:
                    # Create item and add to collection
                    created = zot.create_items([new_item])
                    if created and "successful" in created:
                        zot.addto_collection(collection_key, created["successful"]["0"])
                added_count += 1

        except Exception as e:
            lgr.error(f"Error processing entry {citation_key}: {e}")
            error_count += 1
            if on_error == "exit":
                lgr.error("Aborting due to error (--on-error exit)")
                sys.exit(1)
            # Otherwise continue to next entry

    # Summary
    lgr.info("=" * 60)
    lgr.info("Summary:")
    lgr.info(f"  Added: {added_count}")
    lgr.info(f"  Updated: {updated_count}")
    lgr.info(f"  Skipped (unchanged): {skipped_count}")
    lgr.info(f"  Errors: {error_count}")
    if dry_run:
        lgr.info("  (DRY RUN - no changes made)")


def main():
    parser = argparse.ArgumentParser(
        description="Update Zotero collection with BibTeX entries"
    )
    parser.add_argument(
        "--api-key",
        type=str,
        required=True,
        help="Zotero API key (get from https://www.zotero.org/settings/keys)",
    )
    parser.add_argument(
        "--group-id",
        type=str,
        default="5774211",
        help="Zotero group ID (default: 5774211)",
    )
    parser.add_argument(
        "--collection-key",
        type=str,
        default="T8I34DL3",
        help="Zotero collection key (default: T8I34DL3)",
    )
    parser.add_argument(
        "--bibfile",
        type=str,
        default="dandi.bib",
        help="Path to BibTeX file (default: dandi.bib)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Dry run mode - don't actually make changes",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="Verbose logging (DEBUG level)",
    )
    parser.add_argument(
        "--min-match-threshold",
        type=float,
        default=0.95,
        help="Minimum match rate threshold for validation (default: 0.95 = 95%%)",
    )
    parser.add_argument(
        "--on-error",
        type=str,
        choices=["exit", "continue"],
        default="exit",
        help=(
            "What to do on error: 'exit' stops immediately, "
            "'continue' keeps going (default: exit)"
        ),
    )
    parser.add_argument(
        "--act-only-on",
        type=str,
        default=None,
        help="Regex pattern to filter DOIs to act on (e.g., 'dandi.000027' or 'dandi.00002[0-9]')",
    )
    parser.add_argument(
        "--clear-collection",
        action="store_true",
        help="Delete all items from collection before syncing (use with caution!)",
    )

    args = parser.parse_args()

    if args.verbose:
        lgr.setLevel(logging.DEBUG)

    # Parse BibTeX file
    bib_entries = parse_bibtex_file(args.bibfile)

    # Connect to Zotero
    lgr.info("Connecting to Zotero API...")
    zot = zotero.Zotero(args.group_id, "group", args.api_key)

    # Update collection
    update_zotero_collection(
        zot,
        args.collection_key,
        bib_entries,
        args.dry_run,
        args.min_match_threshold,
        args.on_error,
        args.act_only_on,
        args.clear_collection,
    )

    lgr.info("Done!")


if __name__ == "__main__":
    main()
